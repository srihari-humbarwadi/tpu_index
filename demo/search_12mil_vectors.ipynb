{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/srihari-humbarwadi/tpu_index/blob/master/demo/search_12mil_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "8wAw2JV6F4Am",
    "outputId": "1790b590-5392-402a-d05c-517b0d87fb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\n",
      "To: /content/AbstractSimVectors.npy\n",
      "2.59GB [00:23, 111MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-1HED-B-HtuZR9kNtybz9sypVpk2A_fX\n",
      "To: /content/TitlesAbstractsEmbedIds.json.gzip\n",
      "397MB [00:04, 85.7MB/s]\n",
      "--2019-12-29 15:33:22--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.192.176\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.192.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 442460160 (422M) [application/x-tar]\n",
      "Saving to: ‘scibert_scivocab_uncased.tar’\n",
      "\n",
      "scibert_scivocab_un 100%[===================>] 421.96M  28.5MB/s    in 14s     \n",
      "\n",
      "2019-12-29 15:33:36 (30.9 MB/s) - ‘scibert_scivocab_uncased.tar’ saved [442460160/442460160]\n",
      "\n",
      "scibert_scivocab_uncased/\n",
      "scibert_scivocab_uncased/vocab.txt\n",
      "scibert_scivocab_uncased/pytorch_model.bin\n",
      "scibert_scivocab_uncased/config.json\n"
     ]
    }
   ],
   "source": [
    "!gdown --id \"1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\"   # abstract vectors\n",
    "!gdown --id \"1-1HED-B-HtuZR9kNtybz9sypVpk2A_fX\"   # TitlesAbstractsEmbedIds\n",
    "!wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
    "!tar -xvf 'scibert_scivocab_uncased.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "JP2AqdEiQhbS",
    "outputId": "6dee085a-11bb-4003-c36c-2d708ae71b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n",
      "\u001b[K     |████████████████████████████████| 450kB 3.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 860kB 9.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.0MB 17.8MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tpu_index\n",
      "  Downloading https://files.pythonhosted.org/packages/54/96/206a4a991dc25b02d074f3cfe3e388991e6a6ef2926396988aa77eba445c/tpu_index-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /tensorflow-2.1.0/python3.6 (from tpu_index) (2.1.0rc1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.17.4)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (3.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.11.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (1.25.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (0.33.6)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (3.11.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (0.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu_index) (0.1.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (42.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (1.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (0.16.0)\n",
      "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from keras-applications>=1.0.8->tensorflow>=2.0.0->tpu_index) (2.10.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (1.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (2019.11.28)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu_index) (0.4.8)\n",
      "Installing collected packages: tpu-index\n",
      "Successfully installed tpu-index-0.0.1\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "\n",
    "!pip install transformers --quiet\n",
    "!pip install tpu-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "SGov6e8uGO3B",
    "outputId": "a771201b-60c8-459e-b5de-3910be59866d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: 10.44.146.226:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: 10.44.146.226:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.1.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tpu_index import TPUIndex\n",
    "\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DFloyWt7G8ts",
    "outputId": "7214f6d2-ff58-4a56-9215-af173b93515d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1262996, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_embeddings = np.load('AbstractSimVectors.npy')\n",
    "abstract_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwOP4eefMlyI"
   },
   "source": [
    "## Initialize and Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2XA47ckO7x4o",
    "outputId": "b328a5c4-fb96-4805-a97b-1d08a89e01ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:0\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:1\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:2\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:3\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:4\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:5\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:6\n",
      "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:7\n"
     ]
    }
   ],
   "source": [
    "index = TPUIndex(num_tpu_cores=8)\n",
    "index.create_index(abstract_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OR7Cz5mnMtff"
   },
   "source": [
    "### The first search run relatively slow, but the searches that follow  are blazing fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "AhgRH0GiMSME",
    "outputId": "f91ea9d0-87e8-4b4e-c16a-e74e7c9c7bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search running on /job:worker/replica:0/task:0/device:TPU:0\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:1\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:2\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:3\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:4\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:5\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:6\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:7\n",
      "Warmup search time : 41.566 secs\n"
     ]
    }
   ],
   "source": [
    "dummy_vector = tf.random.normal([1, 512])\n",
    "s = time()\n",
    "_ = index.search(dummy_vector, distance_metric='cosine', top_k=20)\n",
    "e = time()\n",
    "print('Warmup search time :', np.round(e-s, 3), 'secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6qMb5NrPhur"
   },
   "source": [
    "  ### Running the search\n",
    "  - We use BERT model to encode paper abstracts as 512 dim vectors\n",
    "  - We then use this embedding vector to search against our index, which has 12.6 million papers indexed.\n",
    "  - Each search takes around 180ms.\n",
    "###### Note: we trained our model to on a slightly different task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Syc0k8Yi4rcz"
   },
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('gs://tfworld/saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K32HklgqAajo"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(vocab_file='scibert_scivocab_uncased/vocab.txt')\n",
    "\n",
    "df = pd.read_json('TitlesAbstractsEmbedIds.json.gzip', compression = 'gzip')\n",
    "embed2Title = pd.Series(df['title'].values,index=df['EmbeddingID']).to_dict()\n",
    "embed2Abstract = pd.Series(df['paperAbstract'].values,index=df['EmbeddingID']).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFwi3CGERRJb"
   },
   "source": [
    " - Select a random paper id from the corpus, or paste any random paper abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "jxkcuP0CDNKM",
    "outputId": "8988c0a6-bc0b-4b1e-933f-b921253d51ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : \n",
      "('Open circuit fault diagnosis for the power electronic converter stages using '\n",
      " 'ANFIS algorithm')\n",
      "\n",
      "Abstract : \n",
      "('This paper demonstrates a fault detection and location for the open circuit '\n",
      " '(O.C) faults in the all power electronic converter stages including; the '\n",
      " 'three-phase rectifier, the dc-dc converter, and finally the single-phase '\n",
      " 'inverter. The proposed fault diagnosis is based on the adaptive neuro-fuzzy '\n",
      " 'inference system (ANFIS) algorithm. The inputs to the ANFIS unit are the '\n",
      " 'voltage and the current measurements of the power converter stages after '\n",
      " 'they undergo several signal processing operations so that they could '\n",
      " 'efficiently reflect the fault occurrence and behavior. The output of the '\n",
      " 'ANFIS unit is utilized as an index in order to identify the O.C fault in the '\n",
      " 'power converter. Then, it locates the fault within the three different '\n",
      " 'stages of the converter.')\n"
     ]
    }
   ],
   "source": [
    "embed_id = 108712\n",
    "title = embed2Title[embed_id]         # Not used in search\n",
    "abstract = embed2Abstract[embed_id]   # Put your abstract here or use our corpus\n",
    "\n",
    "abstract_encoded = tokenizer.encode(abstract, max_length=512, pad_to_max_length=True)\n",
    "abstract_encoded = tf.constant(abstract_encoded, dtype=tf.int32)[None, :]\n",
    "print('Title : ')\n",
    "pprint(title)\n",
    "print('\\nAbstract : ')\n",
    "pprint(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx1mhvCpOcRJ"
   },
   "outputs": [],
   "source": [
    "s = time()\n",
    "bert_output = model(abstract_encoded)\n",
    "xq = tf.nn.l2_normalize(bert_output, axis=1)\n",
    "e_p = time()\n",
    "prediction_time = e_p - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EhiyvUxrF4xr",
    "outputId": "fd2332b6-b64b-42bb-ee83-da05a5443932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search running on /job:worker/replica:0/task:0/device:TPU:0\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:1\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:2\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:3\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:4\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:5\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:6\n",
      "Search running on /job:worker/replica:0/task:0/device:TPU:7\n",
      "\n",
      "\n",
      "\n",
      "Prediction time  : 0.004 secs\n",
      "Search time      : 0.167 secs\n",
      "Total time       : 0.17 secs\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "Abstract : \n",
      "('This paper demonstrates a fault detection and location for the open circuit '\n",
      " '(O.C) faults in the all power electronic converter stages including; the '\n",
      " 'three-phase rectifier, the dc-dc converter, and finally the single-phase '\n",
      " 'inverter. The proposed fault diagnosis is based on the adaptive neuro-fuzzy '\n",
      " 'inference system (ANFIS) algorithm. The inputs to the ANFIS unit are the '\n",
      " 'voltage and the current measurements of the power converter stages after '\n",
      " 'they undergo several signal processing operations so that they could '\n",
      " 'efficiently reflect the fault occurrence and behavior. The output of the '\n",
      " 'ANFIS unit is utilized as an index in order to identify the O.C fault in the '\n",
      " 'power converter. Then, it locates the fault within the three different '\n",
      " 'stages of the converter.')\n",
      "********************************************************************************\n",
      "Abstract : \n",
      "('This paper presents a fault detection, classification, and diagnoses for all '\n",
      " 'the successive stages of the power electronic converter, including; the '\n",
      " 'three phase rectifier, the dc-dc converter, and finally the single phase '\n",
      " 'inverter. The paper provides a number of proposed algorithms for the open '\n",
      " 'circuit fault diagnoses of these stages. The inputs of these algorithms are '\n",
      " 'the voltage and current measurements of these stages after they undergo '\n",
      " 'certain signal processing so that the inputs of the proposed algorithms '\n",
      " 'could efficiently reflect the fault occurrence and behaviour.')\n",
      "********************************************************************************\n",
      "Abstract : \n",
      "('This paper is concerned with the fault diagnosis of three-phase full-bridge '\n",
      " 'rectifier. A new approach is proposed to extract the fault features in both '\n",
      " 'frequency and time domain. The integrated features are used for the training '\n",
      " 'of an LM-BP neural network, which is then applied for the fault '\n",
      " 'classification. The simulation experiments are implemented on the fault '\n",
      " 'diagnosis model built in MATLAB/Simulink, and the success of the approach '\n",
      " 'has been confirmed by the simulation results.')\n",
      "********************************************************************************\n",
      "Abstract : \n",
      "('To realize real-time fault detection in power devices and enhance '\n",
      " 'reliability of inverter circuits, this paper proposes a detection method '\n",
      " 'based on Park’s transform algorithm and neural network. Park’s transform is '\n",
      " 'applied to obtain the three-phase current base wave amplitude as the '\n",
      " 'characteristic variable for fault detection. Faulty switch devices can be '\n",
      " 'located using a backpropagation neural network in combination with simple '\n",
      " 'logic analyses. The simulation results verify the effectiveness and the '\n",
      " 'feasibility of the proposed method.')\n",
      "********************************************************************************\n",
      "Abstract : \n",
      "('In this paper, an improved Dempster-Shafer evidence theory fusing '\n",
      " 'Back-propagation neural network and Classification and regression tree was '\n",
      " 'presented to improve the accuracy of three-phase voltage-source inverter '\n",
      " 'transistor open-circuit fault diagnosis. Firstly, wavelet transform is used '\n",
      " 'to preprocess load current signals. Secondly, open-circuit faults are '\n",
      " 'diagnosed by the processed currents based on BPNN and CART, respectively. '\n",
      " 'Finally, diagnosis results of BPNN and CART are fused in the improved D-S '\n",
      " 'evidence theory on decision level. Experimental results show better accuracy '\n",
      " 'than any single fault diagnosis method, high effectiveness is evaluated.')\n",
      "********************************************************************************\n",
      "\n",
      "Neighbours       : [108712 564035 348470 516151 815582]\n",
      "Distances        : [-0.      0.2532  0.2731  0.2796  0.2801]\n"
     ]
    }
   ],
   "source": [
    "s_s = time()\n",
    "aD, aI = index.search(xq, distance_metric='cosine', top_k=5)\n",
    "e_s = time()\n",
    "search_time = e_s - s_s\n",
    "print('\\n'*2)\n",
    "print('Prediction time  :', np.round(prediction_time, 3), 'secs')\n",
    "print('Search time      :', np.round(search_time, 3), 'secs')\n",
    "print('Total time       :', np.round(prediction_time + search_time, 3), 'secs')\n",
    "\n",
    "print('\\n'*2)\n",
    "print('*'*80)\n",
    "for i in range(len(aI)):\n",
    "  print('Abstract : ')\n",
    "  pprint(embed2Abstract[aI[i]])\n",
    "  print('*'*80)\n",
    "print('\\nNeighbours       :', aI )\n",
    "print('Distances        :', np.round(aD, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmfksXjcIc04"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Nv5KmtIJK0t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "search_12mil_vectors",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
